#model
transformer_model:
  model: "cointegrated/rubert-tiny"
  path_to_state_dict: false
  device: cpu
  dropout: 0.2
  tiny_bert: true
  learning_rate: 1e-6
  batch_size: 8
  shuffle: true
  maxlen: 512

# data
data:
  train_data_path:
  test_data_path:
  text_column:
  target_column:
  random_state: 42
  test_size: 0.3
  stratify: true

# training
training:
  save_state_dict: false
  early_stopping: true
  delta: 0.001
  patience: 7
  num_epochs: 1
  average_f1: macro
  other_metrics:
    - micro
    - weighted
  output_dir: results/